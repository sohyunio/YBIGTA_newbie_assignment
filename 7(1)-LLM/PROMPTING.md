# Prompting Method Performance Report
<br>

## 1. 정답률 비교 결과 (Accuracy Comparison)

본 실험은 **Llama-3.1-8B-instant** 모델을 사용하였으며,  
**GSM8K 테스트 데이터셋** 중 50개 샘플을 무작위 추출하여 수행되었습니다.

| Prompting Method | 0-shot Accuracy | 3-shot Accuracy | 5-shot Accuracy |
|------------------|----------------|----------------|----------------|
| Direct Prompting | 0.80 | 0.78 | 0.80 |
| CoT Prompting | 0.80 | 0.82 | 0.82 |
| My Prompting | 0.80 | 0.84 | 0.88 |

---
<br><br>

## 2. CoT Prompting이 Direct Prompting보다 우수한 이유

### 1) 사고 과정의 명시화
- "thinking step-by-step" 지시어를 통해 모델이 중간 추론 과정을 생략하지 않고 논리적으로 전개하도록 유도했습니다.
- 이는 모델의 연산 그래프를 명시적으로 확장시켜, 복잡한 문장제 문제에서 논리적 비약을 방지하고 정답 도출의 정밀도를 높이는 효과가 있습니다.

### 2) 추론 가독성 증대
- "Show your work clearly"라는 지시를 통해 모델이 복잡한 연산 과정을 체계적으로 나열하게 함으로써, 정답 도출의 근거를 명확히 하였습니다.
- 체계적으로 나열도니 추론 과정은 최종 정답이 추출되기까지의 근거를 명확히 하여, 모델이 스스로 이전 단계의 연산 결과를 참조하며 답을 낼 수 있는 환경을 제공합니다.

### 3) Few-shot의 시너지
- Direct 방식은 정답의 결과값만 학습하지만, CoT 방식은 제공된 예시(Shot)를 통해 '문제를 해결하는 사고의 알고리즘' 자체를 모방(Mimicry)합니다.
- 샷 수가 늘어날수록 모델은 데이터셋(GSM8K)이 요구하는 논리적 전개 스타일을 더 정확히 파악하게 되어, 추론 일관성이 강화됩니다.
---
<br><br>

## 3. My Prompting이 CoT Prompting에 비해 우수한 이유

### 1) 프롬프트 구조의 최적화
- 단순한 줄글 형태의 지시 대신 불릿 포인트(-)를 사용하여 지시 사항을 구조화했습니다.- - 이는 소형 모델(8B)이 겪는 '긴 문장 지시어 무시 현상'을 방지하고, 모델이 각 지시 사항(논리 전개, 형식 준수)을 독립적인 태스크로 명확히 인지하게 하여 Instruction Following 능력을 극대화했습니다.

### 2) 출력 가이드의 명확성
- CoT의 모호한 지시 대신 "You must end with 'Final Answer: #### ...'"라는 **명시적 종료 선언(Stop sequence)**을 지시했습니다.
- 이는 모델이 불필요한 부연 설명을 덧붙이다가 정답 파싱 로직에서 누락되는 문제를 원천 차단하며, 정답 도출의 안정성과 시스템 호환성을 크게 향상시켰습니다.

### 3) 논리적 단계의 명시성
- "Show clear logical steps"라는 표현을 통해 단순한 수식 나열이 아닌, 전제와 결론이 뚜렷한 인과관계 위주의 추론을 압박했습니다.
- 이러한 '압박 프롬프팅'은 특히 5-shot 환경에서 모델이 예시의 논리적 깊이를 가장 정밀하게 모방하게 만들었으며, 그 결과 0.88이라는 최고 정확도를 달성할 수 있었습니다.
---
<br><br>

## 4. 추가 분석 및 고찰
### 1) 성능 차이가 드라마틱하지 않은 원인
- 모델 크기의 한계 (8B parameter): 본 실험에 사용된 Llama-3.1-8B는 소형 모델로, 파라미터 수가 적어 프롬프트 지시사항을 이해하고 적용하는 '인지적 용량'에 한계가 있습니다. 따라서 shot 수가 늘어나더라도 댛여 모델처럼 비약적인 성능 향상이 나타나지 않고 성능 포화(saturation) 상태에 빠르게 도달하는 경향을 보입니다.

- 기본 모델의 우수한 zero-shot 성능: direct 0-shot에서 이미 0.80의 정확도를 보인다는 것은, 해당 모델이 GSM9K와 유사한 데이터로 이미 충분히 사전학습(pre-training)되었음을 시사합니다. 기본 체급이 높기 때문에 추가적인 튜닝(prompting)을 통한 마진이 상대적으로 적게 측정된 것이라고 분석할 수 있습니다.

### 2) Direct와 CoT의 정확도 차이가 적은 이유
- 연산 오류의 누적: CoT는 추론 과정을 길게 작성하기 때문에, 중간 단계에서단 한번의 사칙연산 실수만 발생해도 최종 답안이 오답 처리되는 '누적연산오류(cascading errors)'에 노출됩니다.
반면 Direct는 중간 과정 없이 직관적으로 답을 내어 이러한 연쇄 오류에서 자유롭기 때문에, 소형 모델에서는 두 방식의 격차가 줄어들 수 있습니다.

### 3) shot 수 증가에 따른 성능 정체 분석
- context window 내의 노이즈: 샷 수가 늘어날수록 프롬프트 길이가 길어지며, 모델이 처리해야 할 정보량(context)가 많아집니다. 소형 모델의 경우 입력된 예시들이 오히려 noise로 작용하여 모델의 집중력을 분산시킬 수 있으며, 이로 인해 3-shot과 5-shot 사이에서 성능이 소폭 상승하거나 정체되는 현상이 발생합니다.

### 4) 표본 수 제한에 따른 통계적 유의성 고찰
- 본 실험은 자원 및 시간의 제약으로 인해 GSM8K 테스트셋 중 50개의 샘플을 무작위 추출하여 수행되었습니다.
- 50개의 표본 크기에서 관찰된 2~4%의 정확도 차이는 모델의 성능 우위를 확정 짓기에는 통계적 유의성(Statistical Significance)이 다소 부족할 수 있으나, 프롬프트 구조 변화에 따른 일관된 성능 향상 경향성을 확인했다는 점에 의의를 둡니다.
- 이에 본 보고서는 수치상의 절대적 비교를 넘어, 프롬프트 설계 방식이 모델의 추론 프로세스에 미치는 영향을 정성적으로 해석하는 데 중점을 두었습니다.